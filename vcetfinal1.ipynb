{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re\n",
    "nltk.download('stopwords') # load english stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing in the digital age begs us all to ac...</td>\n",
       "      <td>Marketing, life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two small businesses from completely different...</td>\n",
       "      <td>technology , transform, innovate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To help us understand how to maintain focus in...</td>\n",
       "      <td>digitalmarketing, focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Courtney shares her experience as a 2-year Cis...</td>\n",
       "      <td>marketing, intern , treasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At Cisco Connect India, we discussed marketing...</td>\n",
       "      <td>marketing , experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  \\\n",
       "0  Marketing in the digital age begs us all to ac...   \n",
       "1  Two small businesses from completely different...   \n",
       "2  To help us understand how to maintain focus in...   \n",
       "3  Courtney shares her experience as a 2-year Cis...   \n",
       "4  At Cisco Connect India, we discussed marketing...   \n",
       "\n",
       "                               Tags  \n",
       "0                   Marketing, life  \n",
       "1  technology , transform, innovate  \n",
       "2           digitalmarketing, focus  \n",
       "3      marketing, intern , treasure  \n",
       "4            marketing , experience  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:/Users/chand/Downloads/archive/train.csv')\n",
    "\n",
    "# 70-30% random split of dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['Review'].values, dataset['Tags'].values, test_size=0.3, random_state=42)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello team vortex okay\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = list((stopwords.words('english')))\n",
    "\n",
    "def text_prepare(text,join_sumbol):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    # lowercase text\n",
    "    text = text.lower() \n",
    "\n",
    "    # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE,\" \",text,)\n",
    "\n",
    "    # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = re.sub(BAD_SYMBOLS_RE,\"\",text)\n",
    "    text = re.sub(r'\\s+',\" \",text)\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = f'{join_sumbol}'.join([i for i in text.split() if i not in STOPWORDS])\n",
    "    \n",
    "    return text\n",
    "\n",
    "tests = [\"Hello , this is Team <Vortex> * are you okay?\"]\n",
    "for test in tests: print(text_prepare(test,' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x,' ') for x in X_train]\n",
    "X_test = [text_prepare(x,' ') for x in X_test]\n",
    "y_train = [text_prepare(x,',') for x in y_train]\n",
    "y_test = [text_prepare(x,',') for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marketing digital age begs us act little like scientists labs internet grand petri dish marketers today',\n",
       " 'quantifying measuring engagement around content every single marketing activity planned goaled tracked optimized common context enabling clear understanding relative impact',\n",
       " 'help us understand maintain focus rapidly everevolving landscape spoke devin hood ciscos director digital marketing',\n",
       " 'cisco put data work transform digital marketing decision making capturing organizing visualizing customer data also involves nurturing datadriven culture',\n",
       " 'cisco connect india discussed marketing b2b technology buyers role marketing buying process best engage customers via superior customer experience cx',\n",
       " 'courtney shares experience 2year cisco marketing intern virtual 2020 internship enabled add value team',\n",
       " 'michelle chiantera shares 3 elements digital marketing stand test time']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marketing,life',\n",
       " 'marketing',\n",
       " 'digitalmarketing,focus',\n",
       " 'marketing,digitalmarketing,trends',\n",
       " 'marketing,experience',\n",
       " 'marketing,intern,treasure',\n",
       " 'digital,world']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top three most popular tags are: marketing,digitalmarketing,life\n",
      "Top three most popular words are: marketing,digital,cisco\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# Dictionary of all tags from train corpus with their counts.\n",
    "tags_counts = Counter(chain.from_iterable([i.split(\",\") for i in y_train]))\n",
    "\n",
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = Counter(chain.from_iterable([i.split(\" \") for i in X_train]))\n",
    "\n",
    "top_3_most_common_tags = sorted(tags_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "top_3_most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(f\"Top three most popular tags are: {','.join(tag for tag, _ in top_3_most_common_tags)}\")\n",
    "print(f\"Top three most popular words are: {','.join(tag for tag, _ in top_3_most_common_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
